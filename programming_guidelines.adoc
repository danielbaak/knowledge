:encoding: UTF-8
// The markup language of this document is AsciiDoc

= Programming guidelines

This document is about programming language agnostic programming guidelines.
See also ++C&plus;&plus;_guidelines.txt++.


[[cost_effective]]
== At the heart: cost effective

At the heart: (Cost) effective work (user visible productive features per time
unit).  Both in short term (mind time to market) and long term (be able to
continuously improve product with lower costs than earnings).

The whole system must be easy to understand at any time, so at any time there
is a high probability that a modification can be made quickly and correctly.
If an mistake is made nevertheless, high probability to discover quickly that
a mistake was made and high probability to be able to quickly fix the mistake
correctly.


== General / Basic Axioms

Learn the rules so you know how to break them properly.  Guidelines help to
not overthink -- but don't stop thinking.

[[KISS]]
- KISS principle -- Keep it simple, stupid.  Keep simple things simple.  Don't
  make complex things unnecessarily complex.  Nearly all principles to achieve
  cost effectiveness are based on that idea in one way or the other.

[[easy_to_use_correctly]]
- Make an entity easy to be used correctly and hard to be used incorrectly.
  Mind Murphy's law: Anything that can go wrong, will go wrong (sooner or
  later).  Similarly: to err is human (i.e. for a human it is especially
  likely that if he can do an error he will, probably rather sooner than
  later).  Consequently if something can be used incorrectly, it will be used
  incorrectly, and that will happen the sooner and the more likely the more
  clients / usages there are.  It's e.g. hard if the client must not forget to
  do certain actions, even worse when that must be in a certain order, and /
  or when arguments must fulfill a predicate.

- You aren't gonna need it (YAGNI): Don't implement a feature until you really
  need it now. Comes down to <<KISS>>: Don't introduce complexity if it's for
  certain that it is needed.

- Make common use cases brief and easy to use, while not making seldom use cases
  impossible to use.

- Clever programmers like writing clever code, but we don't like maintaining
  clever code.  Debugging is twice as hard as writing the program in the first
  place.  So, if you're as clever as you can be when you write it, how can you
  debug it?
+
Not having to be smart is a good sign. It's good if we _don't_ have choices,
  then we can do it only exactly one way, and we don't have to and don't try
  to be smart about making apparently good choices.

- Code is read much more often than it is written. Thus it pays off to invest
  time in writing readable, comprehensible code.

[[redundancy]]
- Redundancy is the primary enemy of a well-designed system.  Opposite of
  <<reuse>>.  Similarly: Don't repeat yourself (DRY). Applies to everything:
  code, data, comments, ....  Rational: It's _very_ difficult to _each time_
  _correctly_ update _all_ redundant parts if one part changes.  Such a
  difficulty is clearly the opposite of <<easy_to_use_correctly,make an entity
  easy to be used correctly and hard to be used incorrectly >>.

[[reuse]]
- Reuse code, especially (standard) library code, instead of handcrafting
  your own.  Don't reinvent the wheel.  Is essentially the same advice as to
  avoid <<redundancy>>.  In general the standard library code is _much_ better
  tested than anything you will write.

[[SRP]]
- Single responsibility principle (SRP). Each entity (type (class), function,
  variable, ...) should only have one single clearly defined
  responsibility. The UNIX philosophy sais the same in different words: Do One
  Thing and Do It Well (DOTADIW).
+
Rational: Then the mind can concentrate on one topic at a time when looking at
  the implementation of an entity, or put the other way round, when thinking
  about how to implement a given task the thought energy can be spend in the
  implementation of a single localized entity.  The more complex a task is, the
  more important that principle is.

[[command_query_separation]]
- Command-query separation (CQS): Asking questions should not change any
  answer.  More formally, methods should return a value only if they are
  referentially transparent (and hence possess no side effects).
+
Queries: Return a result and do not change the observable state of the system
(are free of side effects). The onlye effect is to return a value.
+
Commands (aka modifier, mutator, action): Change the state of a system but do
not return a value. The only effect is to change the state of the system (but
not to return a value).

[[divide_and_conquer]]
- Divide and conquer. Divide a big complicated task (of the program) /
  responsibility into small easy tasks / responsibilities.  Can be seen as a
  consequence of the <<SRP>>: If an entity becomes too large, i.e. currently
  has more than one responsibility, it should be divided into multiple
  entities, each one having a single responsibility.

[[encapsulation]]
- Principle of encapsulation. Everything belonging to a given topic /
  responsibility should be in close proximity, and should thus be put into one
  capsule / entity (typically class or function). Rational: While the mind
  concentrates on this one topic, one has to look only at that single capsule,
  opposed to jump around multiple scattered places.

[[information_hiding]]
- Information hiding is part of doing encapsulation properly: Each capsule has
  an API through which other capsules (called clients) can talk to it, and an
  implementation which is hidden from the clients.  If done right that ensure
  that the complexity of a capsule's responsibility is contained within the
  capsule, and that all clients of the capsule are independent from it.  1) The
  potentially many clients are not forced to also have to know any of the
  complexity, that's solely the one single capsule's problem.  2) As long as
  the capsule does not modify the API to it's clients, it can freely modify
  its implementation while all clients can remain unmodified.

- Explicit is better than implict, because intentional is better than
  accidental.  Specialization of <<KISS>>.

- On ``unintentional point of customization'' (probably specialization of the
  above):  E.g. operator overloads, in particular a) defined in wrong
  namespace b) used in a way that allows unintentional point of customization.

- About APIs and relationships: The client should have to know as few things
  as possible (i.e. do <<divide_and_ conquer>> properly).  I.e. make the API
  as simple and thin as possible.
  * Heuristic: Choose the weakest relationship that is practical (e.g. see
    `prefer composition over inheritance').
  * Formal API: A change forces clients to recompile.  Thus the smaller the
    smaller the likelihood of change, i.e. the faster overall compile
    times.  Note the whole formal API is a tree of formal APIs, types
    referenced also have a formal API which needs to be known /
    parsed.  Forward declarations are maximally small.
   ** Accessible (and thus also visible) part of formal API:
   ** Visible but not accessible part of formal API: A change requires clients
      to recompile although not really needed.
  * Semantic API: The less complexity a client has to know, the easier it is
    to correctly use the API.

- The smaller the visible API to an entity is and the more general / abstract
  the types are it uses, the less things a client dependents upon, i.e. the
  more things can be changed without being forced to modify clients or without
  recompiling clients.

- Clients should depend on interfaces (others say `abstractions'), so the
  concrete class (others say implementation) implementing that interface can
  be exchanged without modifying the client.  It is implied that this
  relationship is via an indirection (using a e.g. a pointer), so 1) the
  concrete class can be exchanged at run time 2) the client must not be
  modified at all.  Without indirection, the concrete class can only be
  exchanged at compile time and involves a modification of the client,
  although a simple, relatively safe one.  This is more important if there are
  many clients and/or not all clients can be modified if a need would arise
  and is less important if there are only few clients, in near locality, and
  it is ensured that all clients could be changed.  I.e. make the interface as
  simple and thin as possible.
  * E.g. getter/setter method instead direct access to a datum, since the way
    the datum is determined / calculated can now be exchanged.
  * E.g. use pure abstract types opposed to concrete types on the API, since
    concrete sub types of those types can more easily exchanged.

- The less clients have access to an entity, the less clients are affected by
  a change to the entity which is visible to the clients.  It's an special
  advantage if the set of those clients is known.  E.g. only members have
  access to private members; the set of members is both limited and known and
  also hopefully small.  On the other hand, all derived classes have access to
  protected members, and everybody has access to public members, which is in
  both cases an unknown / potentially unlimited amount of clients, i.e. it can
  be impossible to find all of them.  Then again in practice when you don't
  write a library, it's most of the times quite easy to find all clients
  accessing the public / protected interface.

- Use polymorphism (sub typing aka inclusion polymorphism or parametric
  polymorphism or dynamic polymorphism) aka program to an interface (meaning
  (base)type), not an implementation (meaning direct member where the type of
  the instance can't be changed at all, and also meaning indirection to an
  other type which should be as close to an pure abstract (aka interface) as
  possible): The implementation of X depends only on the API of a `base type'.
  X can then work with any concrete type fulfilling that API.  I.e. X's
  behaviour can be affected without modifying X itself.  One way of
  implementing the O of SOLID.

- Prefer {immutable data, unaliased mutable local data, unaliased mutable
  thread local data} (in this order of preference) to {mutable process global
  data, mutable data on heap}, because the former set is inherently thread
  safe.  The more general variant of this advice is: prefer data that needs no
  mutex protection over data that does need mutex protection.  Naturally again
  based on <<KISS>>, getting concurrency related issues right is very
  difficult.

- Dump classes / layers should depend on intelligent classes / layers (better
  even have an abstraction in between, see DIP).  It's better if the dumber
  classes need to be changed after a change in a smarter class than vice versa
  since it is a simpler task.

- The boy scout rule: ``Always leave the campground cleaner than you found
  it.''.  Improve the code base step by step.  Broken window theory: humans
  are likely to keep clean code clean and are also likely to let decay rotten
  code even more.

- Robustness Princliple (aka Postel's Law): Be conservative in what you do, be
  liberal in what you accept from others. However some say that this is too
  gentle, they say you should also be conservative in what you accept from others.

[[prefer_immut_to_mut]]
- Prefer immutable objects to mutable objects.  Rational: Largely based on
  <<KISS>>.  Const objects are easier to reason about. They can't be
  modified. They are inherently thread safe.  Larger opportunity to make
  optimizations for the compiler.  Members should not be public in general,
  but if they are at least const then class invariants can still be enforced.
  Classes meant for immutable objects exclusively are easier to implement than
  their counterparts which allow mutable objects.

- What is clean code? Catch-phrases from answers of programming gurus:
 * simple
 * reads like prose
 * logic is straightforward
 * does not obscure the writters intent
 * each routine you read turns out to be pretty much what you expected
 * does one thing well
 * provides one way, rather than many, for doing one thing
 * minimal dependencies/API


== Naming

A program is made up of names. Having good names is one of the most important
parts, if not the most important part, to make a program comprehensible.

- Code should read as English prose when read from left to right -- and do
  exactly, without any surprises, what the average reader understands from
  that English prose.  Programs should be written for people to read, and only
  incidentally for machines to execute. When code just reads like prose,
  without the needs for comments, then you accomplished the goals of good
  naming.
+
Try different names, look at the resulting code that uses the name, how it
  feels / reads.

- Choose names which _directly_ express the intend of what is
  accomplished. Use intention revealing names.

- Expressed from the other side: Avoid mental mapping. Names which do not
  directly express intend require mental mapping.  The readers mind should not
  be troubled with unneeded transformations / indirections. That only drains
  mental power; less mental power is available for the important stuff. When
  each reader has to do transformations in his head, sooner or later one will
  make a mistake. Most very short names (a,b,x,y,tmp) are used as placeholder,
  and the reader always has to map them to the actual concept.

- A name should be short and sweet and to the point (German: kurz knapp und
  prägnant).

- When the single responsibility principle is vioalated, e.g. when a variable
  / type does more than one thing, it is likely that you can't come up with a
  good name. Or vice versa, if you have troubles comming up with a good
  acurate name it can be a sign that the SRP is violated.

- Use pronouncable names. The human brain is good at words, which are by
  definition pronouncable.

- Be consistent. The same thing / concept has always the same name, and
  exactly same spelling. So the reader doesn't need a table for which names
  are synonyms.

- Make meaningfull distinctions. In a set of similar but slightly different
  things, be especially carefull in naming them. E.g. the names could point
  out what the similarity is, but also what the individual
  difference is. Don't use noise words to make a distinction. It's then only a
  pseudo distinction. Customer instead customerInfo, account instead
  accountData.
+
As the feature set gets bigger and bigger, names must change, when new
  names have similarities/differences with existing names to make those
  similarities/differences clear.

- Don't be cute. Don't show off your smartness. Everyone should be able to
  read the code. Choose clarity over entertainment value. Bad examples: whack
  for an premature abort. r for an url with host and

- Avoid disinformation. E.g. inconsistent naming. Words that have different
  meanings in the business language than in the programming language.

- Avoid noninformation. Words like manager, processor, data, info are
  non-informative.

- Use solution/problem domain names

- Use nouns for types. Use imperative verbs for functions being a command (aka
  procedure) (don't use `set...\'), use nouns for functions being a query
  (don't use `get...').

- If an identifier declaration _requires_ a comment, it's a smell.

- If the brief part of the comment doesn't use the same words that make up the
  identifier name, it's a smell.

- Length of identifier should correspond to the size of its scope. Local names
  can be short, members can be medium, class/type names shoudn't be short.
  Shorter names are generally better; however they must be clear in their
  whole scope.

- Don't be afraid of renaming. The better readability pays off for all future
  reading of the code.


References:

- Chapter 2 of "Clean Code", Robert C. Martin


== Comments

- The code is the truth.  It is the _only_ source of truly accurate
  information.
+
Thus code must largely document itself.  Code must be easily comprehensible by
  human readers.
+
If the comment does not agree with the code, it is not worth mutch. Thus code
  must largely document itself. Compilers don't read comments, i.e. the
  validity of comments is not checked.
+
Self explanatory code which truly doesn't need comments.  Better spend
  energy in self explanatory code than good comment.  If you feel like writing
  a comment, think if you not better cleaned up the code.  Use well-named
  variables or methods instead comments.  Possibly introduce new variables or
  sub methods.

- If you do have Comments, they must not be redundant to the code. Comments
  must not parrot the code.  If there is a comment, it should provide
  additional information that is not readily obtainable from the code itself.
+
A comment that is redundant to the code, i.e. that parrots the code, is likely
  that it becomes an lying comment, due to the inherent problems of
  redundancy. And a lying comment obviously leads to problems.

- However, whether the code really is self documenting and whether it really
  is comprehensible should not just be judged by the author. Show the code to
  others, make code reviews.

- If a programmer can't express herself by writing comprehensible code, why
  should she suddenly be able to express himself by writing comprehensible
  comment.

- If too many comments are bad, then experience will tell developers to just
  skip reading comments. Thus the few comments that are good and really should
  be read will be skipped too. Bad comments are just clutter, distracting from
  the important stuff.
+
Likewise, if comments are rather scarce and good, then readers will really
  read them, because then comments catch attention, and from experience
  readers know that the comments really tell non obvious important facts.


=== Bad comments
- Prefer no comment over lying comment.  Note that due to the redundancy
  nature of a comment, any comment becomes a lying comment when one only makes
  changes to a code fragment but not to the comment associated to that code
  fragment, and it is hard to not fall into that trap.

- Prefer no comment over a non-informative comment.  A non-informative comment
  just repeats what is easily understandable by reading the code and thus
  provides no benefits, only costs.  A non-informative comment is highly
  redundant.  E.g. don't have a guideline that _every_ method / member /
  parameter / return value _must_ have a comment.

- When methods just propagate a call, only document the API (or alternatively
  the method which does the actual implementation). The other method's comment
  just refers to there.

- Don't `document' a method at all it's N calls sites, document it only at its
  single definition site.

- Comments behind end of a block stating what the beginning of the block is.
  That is redundant.  It's the job of the IDE to help you quickly identify
  what the beginning of the block is.

- `Banners' marking the beginning of a method definition / declaration.
  That's redundant.  It's the job of the IDE / editor to highlight method
  definitions / declarations.  At least don't repeat the method name in the
  banner; that's too high redundancy.

- `Banners' describing a large fragment of code in a function.  Better
  refactor the method into multiple smaller methods.

- Commented out code.  It's the job of the revision control system to remember
  old code.  When we really need the code again, it probably won't be usable
  anyway anymore.  Most probably starting from scratch will be faster anyway.

- Don't tell in a comment of a method definition who calls it.  That is
  redundant.  And it should not matter.


=== Where / how to use comments

- Emphasis of things which might be otherwise overlooked

- Warning of consequences.  Prevent others from making dangerous changes
  because an issue is hard too see.

- Make clear to which part a comment applies.  E.g. just before an (if,
  while, ...) block.

- Document why you do it like you did it

- If you can't bring yourself to clean up a messy part, at least write a
  comment which states possible problems (for a bug-searcher) and ideas for a
  improvement



[[optimization]]
== Optimization

- You can't take the right decisions if you don't have the right information,
  and you can't have the right information if you don't meausure with the
  right input data and environment.
+
Measure / profile with real world data and HW (e.g. CPU cache properties are
  important).  Many times even experts are wrong when guessing which of
  multiple variants is more optimal and/or where the hot spots are.

- Premature optimization is the root of all evil.  Prefer clear over optimal.

- Law of diminishing returns: The benefits of a more optimal solution might
  not outweigh the costs of increased complexity.  It's much easier to make a
  slow correct program fast than to make an fast incorrect program correct.
  Most programs are I/O bound anyway, not CPU bound.

- But also don't overshoot by making it too simple or care too less about
  optimizations: Make it as simple as possible, but not simpler.  Don't
  pessimize prematurely: prefer more optimal when equally clear.  Always look
  out for inefficiencies where you can get the task done with less work and
  equally clear code.  A lot of small inefficiencies add up and are difficult
  to profile, since its a lot of small things that make the program slow.


=== Measurement

- Measure with real world data, with real world builds (i.e. typically release,
  i.e. typically with optimizations), on real world HW, on real world ....

- Measure different things, and visualize each measurement in different way.
  Each combination (thing measured, visualization variant) highlights a
  different class of problems. Only then we have a good overview of all the
  different problems that we currently have, and can have a sense which one is
  the most serious one and should be attacked first.
  * cpu-off time
  * number of calls of a given method
  * as perf report
  * as perf flamegraph
  * as perf samples displayed in sampling order as flame graph

- On wait time / why seeing wait time (aka cpu off time) can be important:
  Naturaly a thread might wait for many different reasons, not only for another
  thread. I.e. its not that over all threads, work is done. E.g. if there are
  only N entities of a given ressource, when used up, multiple threads wait
  until they get an entity. Often N is one, e.g. a mutex.


== Working methodologies

- Decompose a big complicated task / step (see <<divide_and_conquer>>) into
  small easy tasks / steps.  Each step is focused on a single topic / gain
  (see also <<SRP>>) and has quick <<feedback>>.
+
Topics of resulting leaf steps: 1) add / modify a specification aka test
  which necessarily makes a test fail 2) make the test green by modifying
  productive code to fulfill the new / modified specification 3) optimize test
  or productive code.
+
Top level optimizations: optimize structure aka do a refactoring, optimize
  resource usage at build time aka optimize build time, optimize run time aka
  optimize resource usage at run time.

[[feedback]]
- Quick feedback for each step, the closer in time the better, the less manual
  work (slow, error prone) -- i.e. the more automated work (fast, repeatable)
  -- for getting feedback the better.  Each step should be accompanied by a
  feedback whether the step was made correctly.  <<pair_programming>>, peer
  <<reviews>>, Build tools (compiler, linker, analysis tools (static,
  dynamic)), automated tests (locally (typically unenforced) and enforced as
  part of continuous integration), manual tests.  High level steps have high
  level tests associated, and leaf steps have low level tests (i.e. unit
  tests) associated.

- The earlier bugs / problems are detected the cheaper. Try that bugs don't
  even find their way into the code base.
  * Find problems on the fly while editing: Configure IDE to run the following
    points on the fly in the background and make the found problems apparent
    to you, e.g. by highlighting them in the editor.
  * Find problems at (local) build time: as high warning level as possible,
    make warnings errors, prefer compiler errors over linker errors.
  * Find problems at (local) `extended' build time: automated tests,
    static/dynamic code analysis.
  * Problems which only occur at run-time are a risk. Especially those in code
    that is seldom executed at run-time. Thus make sure automated tests have a
    high code coverage.

[[pair_programming]]
[[review]]
- Do pair programming and do code reviews. Rational: additionally to benefits
  of <<feedback>>: Two eyes see more than one.  Distribution of knowledge
  (code base, working methodologies, tools, ...).  Less chance of allowing
  oneself to be sloppy.

- Take the time to go fast. The primal conundrum: Experience shows that a
  messy code slows you down. Yet you feel the pressure to make messes in order
  to meet deadlines. The *only* way to make the deadline / to go fast is to
  keep the code clean.

- `Definition of done': A feature / bug is not finished until it has
  associated automated tests, is properly documented / commented, the final
  code is comprehensible (i.e. required refactorings are done), etc.
+
LeBlanc's law: ``Later equals never''. That is, if you don't finish a task
  properly now, inclusive all needed tests and refactorings etc., you will
  never do the cleanup. Thus technical dept piles up. Sooner or later you will
  have to pay back the dept. Often just before you want to do a release: you
  will pay endless hours of hunting bugs.

- When attacking a problem, e.g. improve efficiency/performance, finding a
  bug, and after some initial investigation you have different leads, then
  don't follow one lead for a too long time. Especially when stuck, step back
  and analyze the situation. Alternate between the leads, like a task
  scheduler, to avoid being stuck in a `hard' lead and avoid missing
  evaluating an `easy' lead.

- If in deep shit, step back and honestly analyize what's going wrong and take
  countermeasures. Even if that means having to admit having made mistakes, or
  admiting not being good at a given thing/task, or having to go through
  difficult discussions. `D Wahret muess uf de Tisch'.

- Store gained information, so it's not lost. Even more so if the information
  is not easily retreivable again. The cost is information management.

- Do it or leave it. Leave it means really leave it. Don't put it on a
  list. That list will get too big to be of any use.  If the problem persists
  and is truly a problem, it will not be forgotton but pop up again.


== Unsorted

Object relationships:
Composition:
  Aggregation: has-a / owns-a
  Association aka acquaintance aka using: knows-a
Inheritance: is-a (in terms of Liskov)

Ways of implementing:

In any case:

- Free implementation
In case of composition:
- Delegation aka forwarding: Optionally also passing the
original receiver as parameter
In case of inheritance:
- Overriding: replace implementation of base class by an own free implementation
- Inheriting: overtake implementation of base class without modifying it

We can't look into the future, things/plans/...  change.  Base decisions on as
much facts as possible, opposed to assumptions.  How about experience?.  Plans
seldom work.

!!! Differentiate between type definitions and class implementations.  This
is a semantic differentiation, formally in most languages there is no
distinction.  The heuristic is to use interfaces (aka pure abstract classes) as
type definitions !!!

Dependency between a `server' type and an `client' type.  Client is completely
independent of point 2, the implementation of the `server' type.  Depending on
the changes to 1, the client needs only to be recompiled, or in worse cases,
modified.
1. API between client and implementation
 a. Formal contract in form of a (full) declaration of the type /
    function.  Optionally sometimes a simple forward declaration of a name is
    good enough.
 b. Semantic contract in prose to specify additional things which can't be
    specified in the syntax of the programming language.
2. Define aka implement a type / function, naturally fulfilling contract
   defined in 1.

Name ranges +first+, +last+ (or even +last_incl+) to make clear that the last
is inclusive.

Code mess is proportional to Fö&amp;&amp;s per minute.

A cache shall also store that a key is not available in the src, to distinguish
between cachemiss and cachehit-thereIsNothingInTheSource


== Class design


=== Inheritance vs Composition

Inheritance is a very strong coupling and has a couple of drawbacks:

- The sub type _must_ fulfill Liskov

- L of SOLID: Liskov aka "is-a" aka "works-as-a".  I.e. do sub typing correctly,
  i.e. do D of SOLID correctly.  Note that the rules apply to the whole API,
  i.e. inclusive the semantic part.  Note that when using private inheritance,
  you're not creating a sub type, i.e. there is no obligation to fulfill
  Liskov.
+
The Liskov substitution principle (LSP) is a particular definition of a
  subtyping relation, called (strong) behavioral subtyping.  Formally: Let
  ɸ(t) be a property proveable about objects t of type T. Then ɸ(s) should be
  true for objects s of type S where S is a subtype of T.  Informally: If S is
  a subtype of T, then objects of type T may be replaced with objects of type
  S without altering any of the desirable properties of the program.
+
Regarding functions of a subtype: Pre conditions must be equal or widened, post
  conditions must be equal or narrowed.

- The semantic API of a base class for its sub classes is often not trivial,
  at least its often more complex than the semantic API of the public
  interface.  A meaningful subclass implementation most probably needs to know
  how and when the base class calls overridable methods.  I.e. the base class'
  implementation details become part of its the semantic API.  That's why it
  is said that inheritance breaks encapsulation.  Note that in a composition
  relation, there are no such `callbacks', which greatly simplifies the
  contract there.  An method in a subclass overriding a method of the base
  class might be required to call certain methods, such as
  e.g. it's counterpart version in the base class.  Also a sub type (at least
  in most programming languages) inherits automatically methods of its base
  class.  Thus when modifying a base class by adding a new method, that might
  break a subclass, e.g. because invariants the subclass establishes are not
  established by the new automatically inherited method.

- The above point also means that the single responsibility principle is often
  weakened: a base class can not just focus on it's own responsibilities, but
  must also spent mental energy into the collaboration with it's sub classes.
  Likewise a sub class must spend mental energy to properly implement the
  contract with it's base class.

- When the sub type adds a new method, and later the base type also adds a
  method with the same name (*to-do*: how do access rights affect the outcome
  ?!!), things get ugly.

- The declaration of a sub type needs the full declaration of the base type,
  only forward declaration of the base type is not sufficient.

- Is a static relationship which is established at compile time - opposed to
  composition, which can be modified at run time.
+
Mind that the set of sub classes is unlimited, i.e. we may not even have access
  to all sub classes.  I.e. it's not possible to make a change in a base class
  that would force a change in a derived class.  Also its not easy to
  implement an non-pure abstract class which is suitable as a base class
  (*to-do*: explain why!).

- When thinking about to inherit D2 from a concrete class D1, think about
  introducing a new abstract class A from which both D1 and D2 inherit.  That
  forces you to think about the design, to extract the common abstraction
  between D1 and D2.

- It's easiest if an (pure) abstract class does not call any overridable
  methods.  The more own overridable methods a base class calls (which is
  more likely the more methods it implements, i.e. the less close to pure
  abstract it is), the more likely it is that the contract how to correctly
  implement overriding methods gets complex.  Also that contract can only be
  in comments / documents, not in the syntax of the language.

- How to prohibit sub classing of a given class:
 ** Make class final (Java)
 ** Make constructor private and provide public static factories instead.
 ** Document that it's not intended for sub classing

- If a class is intended for sub classing, document that fact and document
  when and how overridable methods are called.

- C&plus;&plus;: Inheriting from a concrete class makes implementing
  operator= difficult. (*to-do*: why? i.e. what class of other
  operators/methods are also difficult to implement?)

- C&plus;&plus;: Inheriting from a concrete class enhances chances that you
  try to treat arrays polymorphically, because arrays of such concrete base
  types can exist, whereas arrays of abstract base types cannot exits.

- C&plus;&plus;: When a class wants to serve as a base type, it's destructor
  should be virtual.  If it's not, no sub type can have a destructor and no
  sub type can add members, and if the sub type fails those requirements, if
  a sub type is deleted polymorphically through base type pointer, only the
  base sub object is properly destructed, but not the rest of the sub type
  object.

- C&plus;&plus;: *to-do*: object slicing?

- Java: A class that wants to be a base class:
 * Constructor may not call overridable methods, directly or indirectly.  In
   case +Cloneable+ or +Serializable+ is implemented, the same also applies
   to +clone+ and +readObject+.
 * If +Serializable+ is implemented, +readResolve+ and +writeReplace+ must
   be protected rather than private.

- Inheriting from non pure abstract classes imposes a raft of problems.  Either
  avoid inheritance altogether by choosing composition instead.  Or when you do
  inherit, prefer inheriting from pure abstract classes (aka interfaces) to
  inheriting from concrete classes, where as abstract classes are in the gray
  scales in-between, and/or consider choosing private inheritance opposed to
  public inheritance.

- Composition's cost relative to inheritance:
 * run-time cost: 1) forward call 2) in case part obj is accessed via
   indirection, the cost of indirection
 * visual clutter of forwarding methods

- Interface (aka pure abstract) vs impure abstract class:
 * When adding a method to the base class: in case of interface, all sub types
   break to compile.  They have to implement the new method.  In case of
   abstract class, when the new method is non abstract, nothing breaks at
   compile time.  In practice is it however difficult that the new method does
   not break the contract in prose between base and sub classes, and/or the
   contract was not properly fulfilled by either side before adding the new
   method, and the act of adding it makes the bug now apparent.
 * In the lack of multiple inheritance, interfaces can be used at more places
   than (impure) abstract classes.  This disables many design patterns which
   depend upon being allowed to implement interfaces in multiple
   classes.  However also in the presence of multiple inheritance, due to its
   complexity, it's easier to inherit from interfaces.
 * Use `Skeletal implementation' (abstract class) or `simple implementation'
   (concrete class).  Use `simulated multiple inheritance', well to simulate
   multiple inheritance.  A class implements its interfaces by forwarding to
   (private) concrete classes extending skeletal implementation classes.

- Prefer non-overridable methods to overridable methods.  As explained above,
  overridable methods in general complicate the API between base type and sub
  type, in particular the semantic API.
+
Regarding creating test doubles which inherit from the real object
  non-overridable methods are an impediment.  The cure is ... *to-do*



== Data vs Code

Programs transforms data.  The hardware takes machine code and data as input
and has data as output.  The programmer's main responsibility is the
(structure and layout of the) data and the transformation.  Writing code is
`just' his tool.  One needs to know the strengths, weaknesses, limitations of
the hardware at hand (classes like small embedded system, consumer home PC,
server farm, or specific HW, depending on what range of HW the product should
run).

Bad programmers worry about the code. Good programmers worry about data
structures and their relationships.

In fact, I'm a huge proponent of designing your code around the data, rather
than the other way around, [...] I will, in fact, claim that the difference
between a bad programmer and a good one is whether he considers his code or
his data structures more important.


== Redirections

All problems in computer science can be solved by another level of indirection
-- except for the problem of too many levels of indirection.

1. Literal constant.  If used multiple times, there is redundancy.  If
   value(s) are changed or if type(s) are changed, client needs to be
   recompiled.  In the case of type change, the clients potentially also need
   to be modified.

2. Preprocessor macro; adds a redirection at preprocessor time.  Adds reuse /
   elimination of redundancy.

3. Immutable data object whose address is a compile time constant and whose
   value is visible to a client.  Opposed to 2, the indirection is now at
   compile time.
+
*to-do* Depending on the use case more type safety than 2, however that is not
   directly the topic, here it's about benefits of redirection.

4. Data object whose address is a compile time constant.  Relative to 1) adds
   an indirection   Globals (non-TLS)
 * immutable.  value can now
   additionally be modified at compile time without recompiling client.  Note
   that neglecting link seams, there is still only one value for all
   executables, in particular a test cannot change it.
 * mutable.  Value can now additionally be modified at run time.

5. pointer to a data object.  Object can now additionally be substituted at
  run-time.  Also the substitution can be polymorphically.

6. pointer to a data object recursively

7. method whose address is a compile time constant

// * data object whose address is a (compile time) constant offset from a pointer
//   which is not under programmer's control
//  * locals (relative to frame pointer)
//  * struct/class member (relative to +this+)
//  * array member



== References

- Book: Clean Code. Robert C. Martin.
- Book: Clean Coder. Robert C. Martin.
- Book: xUnit Test Patterns - Refactoring Test Code. Gerard Meszaros.
- Book: Working Effectively with Legacy Code. Michael Feathers.
- Book: Design Patterns: Elements of Reusable Object-Oriented Software. Erich Gamma, Richard Helm, Ralph Johnson, John Vlissides.
- Book: Refactoring - Improving the Design of Existing Code. Martin Fowler.
- Video: https://www.youtube.com/watch?v=UjhX2sVf0eg&t=13s[10 Tips For Clean Code]
- Video: https://www.youtube.com/watch?v=ZsHMHukIlJY[ITT 2016 - Kevlin Henney - Seven Ineffective Coding Habits of Many Programmers]
- Video: https://www.youtube.com/watch?v=CzJ94TMPcD8&t=75s[Giving Code a good name - Kevlin Henney]
- Webpage: sourcemaking. https://sourcemaking.com/design_patterns[design patterns], https://sourcemaking.com/antipatterns[antipatterns], https://sourcemaking.com/refactoring[refactoring]



// Local Variables:
// coding: utf-8
// End:

//  LocalWords:  pessimize APIs SRP overridable IXLogger Cloneable readObject
//  LocalWords:  Serializable readResolve writeReplace gotw params inmut mut
//  LocalWords:  TLS overthink refactor
