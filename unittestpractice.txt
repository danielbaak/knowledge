This page contains practical information on how to write unit tests in the Flori project. You should first read page [[Unit Test]], which explains how the Flori project defines unit tests. 

UnitTest2 are proper unit tests using [[Googletest]] and additionally optionally [[Googlemock]]. The old style of Flori's pseudo 'unit tests' is described in page [[UnitTest Practice]].



== PC UnitTest2: Howto create / write UnitTest2 project / test cases / tests ==

In this walkthrough it is shown how to create a new UnitTest2 project using the project DIDispenserSeq as an example, assuming DIDispenserSeq does not yet have a UnitTest2 project. Naturally you do all the following by replacing DIDispenserSeq with your project's name.


=== MS studio project filters & naming conventions for UnitTest2 projects ===

The UnitTest2 MS visual studio projects have the following project filters (aka folders). If you read this manual the first time, and if you are only interested in the practical how to, you may skip this chapter and return to it later.

;TestHelpers
:You may want to create usefull test helpers for certain classes, which can then be used by many tests. Most commonly these are custom printers or custom assertions, see [[UnitTest2_Practice#Good_output_for_good_defect_localization here]]. The naming convention is to append `TestHelper' to the base file name. E.g. in the example of DIDispenserSeq, the files <tt>DINodeTestHelper.(cpp|h)</tt> contain the test helpers for the <tt>CDINode</tt> class.
:Put test helpers for classes being defined in the public interface of a library in the project <tt>DieBonder/PC/UnitTests/PC-UnitTest/FloriMockSupport</tt>, so everybody can profit from them. E.g. printers for CExtendedItemType2 are defined there.

;TestDoubles
:Put the test double classes for classes defined in your main project in this folder. The naming convention is to append the test double type to the base name. In Flori practice this is either Mock or Fake. There is no `stub' class, the mock class is used to create mock objects and stub objects. E.g. in DIDispenserSeq, <tt>CDIPatternMock</tt> is mocking the interface <tt>IDIPattern</tt>.
:Put test doubles for classes being defined in the public interface of a library in the project <tt>DieBonder/PC/UnitTests/PC-UnitTest/FloriMockSupport</tt>, so everybody can profit from them. E.g. the test doubles for our phf items are defined there. The naming conventions are naturally the same as described in the previous paragraph. 

;Tests
:Put your tests here. Each unit (most probably a class) under test gets its and own file. The naming convention is to append `Test' to the base name. E.g. in DIDispenserSeq, <tt>DINodeListTest.(cpp|h)</tt> contain the test case for the class <tt>CDINodeList</tt>. If you make use of a fixture class, it naturally is named after the same principle, thus in the previous example you get <tt>CDINodeListTest</tt>.

;UnitsUnderTestAndDependedOnComponents
:The UnitTest2 project needs to link in the source code under test. To be able to have fast build times in the average case, which is that you work in the UnitTest2 project and only did a few changes, the UnitTest2 project compiles and links the code under test itself. Consequently you need to add the units under test also to the UnitTest2 project. E.g. DIDispenserSeq, having a test for <tt>CDINodeList</tt>, adds (its more like linking a file) <tt>..\Sources\DINodeList.cpp</tt>. To be able to link, you also need to add depended-on components (DOC). E.g. DIDispenserSeq has no unit test for the trivial class <tt>CDIPatternDecisionParams</tt>. However <tt>CDIPatternDecisionParams</tt> is used by (aka is a DOC of) <tt>CDINodeList</tt>, so <tt>..\Sources\CDIPatternDecisionParams.cpp</tt> is added too.

=== Recommended setup and workflow for your private MS visual studio solution ===
This is the recommended, not the required, way how to configure your private MS visual studio solution (..._private.sln). It's up to you where this solution is. 

'''Setup:''' The private solution shall contain the UnitTest2 project (from the UnitTest2 folder), the main project (from the Sources folder) and the UnitTest project (from the UnitTest folder). In the solution's configuration manager, add a solution configuration "Flori UnitTest2 Debug" which only builds the UnitTest2 project with project configuration "Flori Debug" and does nothing with the main project and the (old)UnitTest project. Optionally make an analogous configuration "Flori UnitTest2 Release". Make sure the existing solution configuration "Flori Debug" builds all three projects; likewise for "Flori Release". Concerning project dependencies: typically only the (old)UnitTest project depends on the main project. The UnitTest2 project shall _not_ depend on the main project, so build time for only the UnitTest2 project is faster.

'''Workflow:''' The idea is that most of the time, you work with the solution configuration "Flori UnitTest2 Debug". After each small step of changes to the source code, you can get a feedback by building, which includes running all unit tests. Since the link step of the main project is committed, each time you save that time. To view/edit files of the main project, access them via the main project, as opposed to via the UnitsUnderTestAndDependedOnComponents project filter of the UnitTest2 project. This way UnitsUnderTestAndDependedOnComponents can be a flat list of .cpp files which you almost never look at. To be sure all three projects still compile, at least before pushing build the solution with the solution configuration "Flori Debug", which as described above, builds all projects.

=== Create empty UnitTest2 project ===

Do the following either by hand, or the [[UnitTest2_Practice#unittest2gen|unittest2gen]] tool do the first half of the work for you:

# Copy the folder <tt>DieBonder/PC/UnitTests/PC-UnitTest/Templates/UnitTest2</tt> into folder <tt>DieBonder/PC/Dispenser/DIDispenserSeq</tt>
# Rename the files by replacing `MyProject' with `DIDispenserSeq'
# Create an <tt>.sln</tt> by opening the <tt>.vcxproj</tt> and building it. At the end of the build, the test is automatically run and should be green. 
# Close visual studio and make a copy of the <tt>.sln</tt> and name it ala <tt>DIDispenserSeqUnitTest2_private.sln</tt>. Work with this _private.sln instead the real .sln, see Flori's Git Howto manual for the rationale. Setup your private solution to your liking - the recommended way is described in the previous chapters.

Has to be done by hand; is not yet covered by the unittest2gen script:

# Since approximately each file in the main project will some when have its corresponding test file, the filter hierarchy in the main project and the filter hierarchy in the UnitTest2 project within filter `Test' should be the same. This way there is an easy understandable 1:1 relation. Thus create now the filter hierarchy within the `Tests' filter. E.g. if the main project has the filters `Header Files', `Source Files' and `Teach Menus', you should create these three filters also within filter `Tests'. It's really simple, just complicated to describe - just ask if you didn't got it.
# Optionally commit the new files to Git to have a save point. It should be these 5 files: <tt>stdafx.cpp</tt>, <tt>stdafx.h</tt>, <tt>.vcxproj</tt>, <tt>.vcxproj.files</tt> and <tt>.sln</tt>. 
# As soon as you have pushed the new UnitTest2 project to the central repository, you have to add your new project to the Global UnitTests studio solution: 'Global' Git Project, file <tt>W:\Global\Solutions\FloriSW_UnitTests.sln</tt>. Your new UnitTest project has at least the project dependency to project FloriGMockSupport. A detailed howto is [[HowTo_for_Buildsystem#HowTo_Add_a_New_PC_Project_to_the_Dailybuild|HowTo Add a New PC Project to the Dailybuild]]

=== A simple empty test case ===
In the following example the already existing class <tt>CDINodeList</tt> is our unit under test, for which we want to write a new test case. A test case is a collection of tests. When multiple tests in a test case use common methods (e.g. SetUp or TearDown), or common member variables, a test fixture class becomes handy. A test fixture class is one that derives from <tt>::testing::Test</tt>.

# Open your private MS studio solution containing the UnitTest2 project.
# Add the unit under test source file to the UnitTest2 project: In the solution explorer for the UnitTest2 project, right click the UnitsUnderTestAndDependedOnComponents folder, and using `Add / Existing Item...' add the <tt>../Sources/DINodeList.cpp</tt>. There is no reason to also add the <tt>.h</tt> file. This is a link to the file in the <tt>../Sources</tt> folder, not a copy of the file. Only after all the next following sub steps are done you will be able to build.
#* Add .cpp files of the main project your unit under test depends upon to the UnitsUnderTestAndDependedOnComponents folder within studio's solution explorer. If you forgot to add one, the linker will tell you which files he misses. In this example, our UUT <tt>CDINodeList</tt> depends on the concrete classes <tt>CDIPatternDecisionParams</tt> and <tt>CDINode</tt>.
#* In the project settings (Project/Properties: Linker/Input), add libraries your unit under test uses to the additional dependencies of the linker inputs. For the Flori_Debug configuration add FooUD.lib, for the Flori_Release add FooU.lib. Again, the linker will tell you what he misses. In this example it's <tt>FloriGeometry(U|UD).lib</tt>. 
#* Build to test you did everything right. If you get compile errors, that might be because:
#** The unit under test source code forgot to #include a header files it needs. The main procect can compile because it gets the forgotten header file implicitely from somewhere else, e.g. it's stdafx.h. The right thing todo is to add the #include to the unit under test source code and ''optionally'' also to the stdafx.h of the UnitTest2 project. It's ''not'' the right thing to only add the #include just to the stdafx.h of the UnitTest2.
#** Similary the unit under test code forgot to #import a tlb file it needs. The same solution can applies, but there is an additional solution to consider: It might be the best to #include the associate .h instead of #import the .tlb. It also might be the point to consider splitting foo.idl into foo.idl and footype.idl, as already done by many Flori idl's, and the test can then only include footype.h.
# Under the filter / folder `Tests', add a new .cpp and a new .h file named as the unit under test, but with `Test' appended. In our example that is <tt>DINodeListTest.(cpp|h)</tt>. As content you can use the following templates. Build to get a feedback wether you did it right.

test case template, header file:
<pre>
#pragma once

//..begin "UTF:Includes"
#include "gtest/gtest.h"
//..end "UTF:Includes"

/** */
class CDINodeListTest :
  public ::testing::Test
{
  public:
    CDINodeListTest();
    virtual ~CDINodeListTest();

    // member variables and methods go here
    // remove this comment after reading, it's only intended for the template

  protected:
    virtual void SetUp();    // delete if you don't need it
    virtual void TearDown(); // delete if you don't need it
};
</pre>

test case template, source file:
<pre>
//..begin "UTF:Includes"
#include "stdafx.h"
#include "DINodeList.h"
#include "DINodeListTest.h"
//..end "UTF:Includes"


CDINodeListTest::CDINodeListTest()
{
}

CDINodeListTest::~CDINodeListTest()
{
}

// delete if you don't need it, i.e. if body is empty
void CDINodeListTest::SetUp()
{
}

// delete if you don't need it, i.e. if body is empty
void CDINodeListTest::TearDown()
{
}

TEST_F(CDINodeListTest, MAKE_TEST_NAME(
  given, // see Given-when-then DSL chapter, delete this comment after reading
  when,
  then,
  sothat))
{
  // - Think specification, not test
  // - Fast execution time (<10ms)

  // setup
  // - Corresponds to GIVEN clause of test name
  // - Create UUT and its context (DOC). Put everything in the required state
  //   to be able to exercise the UUT below.
  // - Make clear which object is the UUT by making 'UUT' part of its name

  // mock expectations
  // - corresponds to THEN clause of test name
  // - Define *expectations* (cardinality or order) on mock objects  
  // - Defining (googlemock-)actions on mock/stub objects belongs into 
  //   the above setup section.

  // exercise
  // - Corresponds to WHEN clause of test name
  // - Do something with UUT. Should be only one call, i.e. test only one thing.
  // - By definition, the *only* calls which are tested by this whole test 
  //   are those to the UUT in this exercise section.

  // verify
  // - Corresponds to THEN clause of test name
  // EXPECT_...( expected, actual)   non-fatal, test continues
  // ASSERT_...( expected, actual)   fatal, returns from *current method*

  // tear down
}
</pre>

=== A simple specification (aka test) ===
Write a new specification (aka test): 

<pre>
TEST_F(CDINodeListTest, MAKE_TEST_NAME2(
  Constructor,
  creates_empty_list))
{
  CDINodeList UUTNodeList;
  EXPECT_EQ( 0, UUTNodeList.Size() );
}
</pre>  

The test must honor Flori's [[UnitTest2 Practice#Test rules and guidelines|test rules and guidelines]]. Build project, which includes running the test, and enjoy the green bar. Note that the SetUp and TearDown member methods are not yet used in this example, because our tests so far have no common setup / tear down code that is worth refactoring into a common SetUp / TearDown method. The test name is the specification of what the UUT should do given in prose. It is given using the See [[Given When Then]] DSL.

Write another new specification (aka test). Let it run and enjoy the green bar.

<pre>
TEST_F(CDINodeListTest, MAKE_TEST_NAME2(
  Add,
  increases_list_size_by_1) )
{
  // setup
  CDINodeList UUTNodeList;
  CDINode ANode;
  
  // exercise
  UUTNodeList.Add( ANode );
 
  // verify
  EXPECT_EQ( 1, UUTNodeList.Size() );
}
</pre>


=== Good assertions for good defect localization ===
Google test provides you with a rich set of assertions like <tt>EXPECT_EQ</tt> or <tt>ASSERT_EQ</tt>. Using the most appropriate / dedicated assertion helps to make the test code and the output much more informative, which considerably enhances defect localization, which is one of the important [[Unit Test#definition|properties of a unit test]].

The ASSERT family results in a ''fatal'' failure: the current method (which must have return type void) is exited with <tt>return</tt>. The EXPECT family results in an ''non-fatal'' failure: the test continues to run and at the end, you see the list of non-fatal assertions that failed.

There's a whole bunch of dedicated assertions like EXPECT_EQ (equal), EXPECT_LT (less than), ASSERT_DOUBLE_EQ (equal tailored for doubles) etc. See the list at the bottom of this chapter.

The first argument to most assertion is the expected value and the 2nd argument is the actual value. Use the macros accordingly, else in case of failure the output is a bit confusing.

Before using the very general (and thus maybe too less informative) EXPECT_TRUE or EXPECT_FALSE, consider using [http://code.google.com/p/googlemock/wiki/CookBook#Using_Matchers_in_Google_Test_Assertions Matchers]. E.g. instead <tt>EXPECT_TRUE( ConvertDuration2hhmmss(1.5)=="00:00:01" || ConvertDuration2hhmmss(1.5)=="00:00:02")</tt> write <tt>EXPECT_THAT( ConvertDuration2hhmmss(1.5), AnyOf("00:00:01","00:00:02") )</tt>. The first version's failure output can only contain that the actual value of the boolean expression was false instead true. The matcher in the 2nd version however can accurately describe what was expected and what the actual involved values where. E.g. the output contains the actual value of <tt>ConvertDuration2hhmmss(1.5)</tt>, and the actual value of the arguments to AnyOf (which naturally is more helpfull if these are function calls).

The common practice of first writing a failing test, see it fail, and only then the productive code gives you the opportunity to see the failure message of the test. Improve it if needed by using a more appropriate assertion or other means of improving output, see [[#Good_output_for_good_defect_localization|Good output for good defect localization]].

List of available assertions:
* [http://code.google.com/p/googletest/wiki/V1_6_Primer#Assertions Assertions] 
* [http://code.google.com/p/googletest/wiki/V1_6_AdvancedGuide#More_Assertions More Assertions]
* [http://code.google.com/p/googlemock/wiki/CookBook#Using_Matchers_in_Google_Test_Assertions Matchers in Google Test Assertions]. List of available matchers can be found [http://code.google.com/p/googlemock/wiki/CheatSheet#Matchers here].
* Flori adds more, see [[UnitTest2_Practice#Global_test_helpers|Global test helpers]]
* You can add your own assertions to your unit test. You may want to make use of [http://code.google.com/p/googletest/wiki/AdvancedGuide#Predicate_Assertions_for_Better_Error_Messages predicate assertions]. Consider adding them to FloriMockSupport, if it makes sense that they are available globally.

=== Test rules and guidelines ===

Remember Flori's [[Unit Test#Definition|unit test definition]]: Very fast, high defect localization and high code coverage. From that, from [[Automated Test#Properties|properties of an automated test]] and from further ideas follows:

* A single test should execute in less than 10ms. Googletest's output shows the run time for each test.
* You specify what the UUT should do by writing two redundant specifications, see also [[Automated Test#Program specification forms|program specification forms]]:
*# Test name: Specify what the UUT should do in prose using the [[Given When Then]] DSL
*# Test implementation: Specify what the UUT should do by giving an example (or multiple really simple examples):
*#* Each test has the following five clearly separated sections:
*#** setup
*#** mock expectations
*#** exercise
*#** verify
*#** tear down
*#: Some sections may be absent. Use comment headers as in the test source code examples above to mark the sections. The goal is that it's perfectly clear for each statement to which section it belongs.
*#* The implementation of each test section needs to strongly correspond to the corresponding Given/When/Then clause of the test name, see also the table on the [[Given When Then]] page.
*#* Tips what the test sections should contain is described in the large C++ comment in the test template of the previous chapter. 
* Make clear which object is the unit under test by having the string "UUT" somewhere in its name.
* By definition, ''only'' the call(s) to the UUT in the exercise section is what is really tested. ''All'' other calls are by definition assumed to work and need their own tests elsewhere. See also chapter [[#Definition of what a test really tests]].
* A singe specification (aka test) should specify only one thing. The more things a test tests, the more the defect localization drops: it gets more difficult to understand the test and to interpret the tests' output in case of failure. 
* However sometimes it might make sense to put multiple small examples into one test. For example if the individual examples are really tiny and it really is overkill to create an independent test for each of them. But then be aware that probably each example is actually a sub-specification. 
** As with the whole specification aka test, we want to have a prose form of this (sub-)specification within the test source code ''and'' in the test's output. The format is either 
*** a sentence structured the keywords "given" "when" "then" "sothat" (see [[Given When Then]] DSL) 
*** or a sentence beginning with the keyword "Should". 
** In the test src code, that prose spec should appear before the EXPECT / ASSERT macro. This is because we normally read from top to bottom, and we normally understand prose faster than code.
: For example:
<pre>
TEST(TimeHelperTest, MAKE_TEST_NAME(
    non_valid_input,
    Convert,
    returns_false))
{
    EString spec;

    spec = "Should reject leading and/or trailing garbage";
    EXPECT_FALSE(Convert("x13:00:00 10/08/13x")) << spec;
    EXPECT_FALSE(Convert("x13:00:00 10/08/13")) << spec;
    ...

    spec = "Should reject too large values of ";
    EXPECT_FALSE(Convert("25:00:00 10/08/13")) << spec << "hour";
    EXPECT_FALSE(Convert("13:60:00 10/08/13")) << spec << "minute";
    ...

    spec = "Should reject an %s given with more than two digits";
    auto SpecF = [&spec](const EString& i_s)->EString
    { EString sRet; sRet.Format(spec,i_s); return sRet; };
    EXPECT_FALSE(Convert("130:00:00 10/08/13")) << SpecF("hour");
    EXPECT_FALSE(Convert("13:000:00 10/08/13")) << SpecF("minute");
    ...
</pre>


See also 
* [[UnitTest2_Practice#Cookbook_for_writing_tests|Cookbook for writing tests]]
* [[Automated Test#Properties|Automated Test Properties]]
* [[Unit Test#Definition|Unit Test Definition]]


The rest of this sub chapter is a background discussion for the interested reader only:

About the 5 test phases: The 4 phases setup, exercise, verify and tear down are from the testing schoolbooks. I added `mock expectations', since also the testing schoolbooks say that mocks fundamentally change how a test works: In a `normal' test, the verify section contains the statements which define, whether the test succeeds or not. In a test using mocks, the statements defining whether are tests succeeds or not are statements defining the expectations on the mocks. So also the testing schoolbooks say it should be clear which statements are setting expectations. I take this thought further and propose to have a fifth phase `mock expectations' (coming after phase `setup') to enhance clarity.

=== Definition of what a test really tests ===
By definition, ''only'' the call(s) to the UUT in the exercise section is what really is tested. ''All'' other calls, by definition, are assumed to work fine and thus need their own tests elsewhere. This definition helps to make clear what the current test really tests. It thus also helps to recognize what other tests are needed.

=== A specification (aka test) using a mock object and ON_CALL ===
In this subchapter we want to test the <tt>CDINodeList::FillInPattern</tt> method, which expects an <tt>IDIPattern&</tt> as parameter. In this example, we want to use a mock object using ON_CALL as test double implementing <tt>IDIPattern</tt>. We use the googlemock framework to create the mock object and a mock class. The type of the test double class, here mock, was appended to the base name resulting in <tt>CDIPatternMock</tt>. A fake would thus have been named <tt>CDIPatternFake</tt>. 

1. Add a new file <tt>DIPatternMock.h</tt> defining the class <tt>CDIPatternMock</tt> to the `TestDoubles' filter (aka folder) in the project DIDispenserSeqUnitTest2 and fill it with the content shown below. As you can see, it is pretty easy to define such a class. Build to enjoy the green bar.

DIPatternMock.h:
<pre>
#pragma once

//..begin "UTF:Includes"
#include "IDIPattern.h"
#include "FloriGMock/FloriGmock.h"
//..end "UTF:Includes"

class CDIPatternMock :
  public IDIPattern
{
  public:
    MOCK_METHOD1(GetDispenseAreaXy,EHRESULT(
        tEVecXy& o_vecDispenseAreaXy));
    MOCK_METHOD1(GetPatternClassSelectionMatMgmnt,EHRESULT(
        EMatMgmtPatternClassSelection& o_ePatternClassSelection));
};
</pre>

Definition of <tt>IDIPattern</tt>, displayed here just for reference:
<pre>
class IDIPattern
{
  public:
    virtual EHRESULT GetDispenseAreaXy(
      tEVecXy& o_vecDispenseAreaXy) =0;
    virtual EHRESULT GetPatternClassSelectionMatMgmnt(
      EMatMgmtPatternClassSelection& o_ePatternClassSelection) =0;
};
</pre>

2. We write a a first test for the simplest case, the single dot pattern. As always in TDD, write the test straightforward, you want the good feeling of the green bar as soon as possible. You can refactor once you have the aid of the green bar. More information on what is done in the sample code below is given further below. Build and enjoy the green bar.

DINodeListTest.cpp:
<pre>
#include "DIPatternMock.h"
#include "EVecXy.h"
</pre>
<pre>
/** The expected node list is specified within the requirements dispenser bible,
chapter 'autocalc for epoxy patterns' */
TEST_F(CDINodeListTest, MAKE_TEST_NAME(
    default_single_dot_pattern,
    FillInPattern,
    creates_specified_node_list))
{
  // ! This is NOT a golden sample yet, it needs refactoring !

  // setup
  CDINodeList UUTNodeList;
  tEVecXy vecDispenseArea = { 0.002, 0.002 };
  real64 fCapilaryDiameter = 0.002;
  EVecXy vecWindowSize( 0.0, 0.0 );

  CDIPatternMock SingleDotPattern;
  ON_CALL( SingleDotPattern, GetDispenseAreaXy(_)).
    WillByDefault(
      DoAll(
        SetArgReferee<0>( vecDispenseArea ),
        Return(S_OK))); 
  ON_CALL( SingleDotPattern, GetPatternClassSelectionMatMgmnt(_)).
    WillByDefault(
      DoAll(
        SetArgReferee<0>( eMatMgmtPatternClassSingleDot ),
        Return(S_OK)));

  // exercise
  UUTNodeList.FillInPattern(SingleDotPattern, fCapilaryDiameter,
    vecWindowSize.X(), vecWindowSize.Y());

  // verify
  // the expected values are given 1:1 by the dispenser requirement bible
  ASSERT_EQ( 1, UUTNodeList.Size() );
  CDINode Node0(0.0, 0.0, 0.0); 
  EXPECT_DOUBLE_EQ( Node0.m_fNodeDelayFactor, UUTNodeList.At(0).m_fNodeDelayFactor  );
  EXPECT_DOUBLE_EQ( Node0.m_fXPos, UUTNodeList.At(0).m_fXPos  );
  EXPECT_DOUBLE_EQ( Node0.m_fYPos, UUTNodeList.At(0).m_fYPos  );
}
</pre>

The rest of the chapter explains what is done in the examples above:

The <TT>ON_CALL</TT> macros set up our mock object <tt>SingleDotPattern</tt>. For each method of the interface <tt>IDIPattern</tt> that is called during the test we define the simple actions our stub object should do when the respective method is called. Let's look at the first example: We define the actions how the stub object <tt>SingleDotPattern</tt> reacts <tt>ON_</TT> a <tt>CALL</tt> to <tt>GetDispenseAreaXy</tt>. It <tt>WillByDefault</tt> (i.e. will always) <tt>DoAll</tt> of the follwing: 1) <tt>SetArgReferee<0></tt> (i.e. set referee referenced to by the first reference argument) to <tt>vecDispenseArea</tt>. 2) <tt>Return</tt> <TT>S_OK</TT>. The underline in <tt>GetDispenseAreaXy(_)</tt> means that the parameters with which GetDispenseAreaXy is called is allowed to be anything. Use one underline per paremeter you need to pass, e.g. <tt>foo(_,_)</tt> for a <tt>foo(int,double)</tt> method.

See [http://code.google.com/p/googlemock/w/list google mock] manuals for the very rich set of ways how to set actions. You'll be amazed!

Note that asserting the list size is 1 uses <TT>ASSERT...</TT>, not <TT>EXPECT...</TT>, since we should not continue if that is not the case, to avoid further errors when possibly accessing list elements that don't exist. The further assertions use <TT>EXPECT...</TT>, since we want to know for all of them wheter they succeeded or not; we do not want to stop the test at the first one that fails, in order to have more information what went wrong.

See the implementation of <tt>DINodeListTest</tt> within Git to see cleaned up code afte refactorings
* Use of <tt>SetUp</tt> method for setup code common among all tests of the suite
* No unexplained literals
* Factor out common code fragments
** Custom expectation method <tt>ExpectEq</tt>
** Methods creating objects needed by multiple tests: <tt>MakeANode</tt>, <tt>CreateAPattern</tt>, ...

=== A specification (aka test) using a mock object and EXPECT_CALL ===
First be sure you really want to use EXPECT_CALL and not ON_CALL. If you really do, read on. 

The following defines our <TT>EXPECT_</TT>ations on <TT>CALL</TT>s to method <tt>Foo</tt> of object <tt>SingleDotPattern</tt>:  It must be called exactly <tt>2 Times</tt> with an argument of <tt>3</tt>. Calling Foo(3) not exactly 2 times, or Foo with any other argument any number of times, will make the test to fail.

<pre>
...

// mock expectations
CDIPatternMock SingleDotPattern;
EXPECT_CALL( SingleDotPattern, Foo(3) ).
  Times(2);

...
</pre>

See [http://code.google.com/p/googlemock/w/list google mock] manuals for the extremely rich set of ways how to set expectations and actions. You'll be amazed!

=== A specification (aka test) using faked DB items ===
All Items and IndelItems of type <tt>tPST_ExtReal, tPST_ExtInteger, tPST_ExtStruct, tPST_INDELReal, tPST_INDELInteger, tPST_INDELStruct</tt> are now testable by default. It's possible to use FakeItem's or MockeItem's instead of the real Item's.

All Unittest2 are configured by default to use FakeItem's

For configuring an other type use one of the followed macro's:
* <tt>SET_ITEM_FACTORY()</tt> use real Item's
* <tt>SET_FAKE_ITEM_FACTORY()</tt> use FakeItem's
* <tt>SET_MOCK_ITEM_FACTORY()</tt> use MockItem's

* <tt>SET_INDEL_ITEM_FACTORY()</tt> use real IndelItem's
* <tt>SET_FAKE_INDEL_ITEM_FACTORY()</tt> use FakeIndelItem's
* <tt>SET_MOCK_INDEL_ITEM_FACTORY()</tt> use MockIndelItem's

<pre>
  ...

  //setup
  SET_MOCK_ITEM_FACTORY()

  //exercise
  ...

  //verify
  ...
</pre>

=== Good output for good defect localization ===
Good output / information in case a test fails considerably enhances the [[Unit Test#Definition|defect localization]], which is one of the important [[Unit Test#definition|properties of a unit test]].

==== Custom printers ==== 
If having something like <tt>EXPECT_EQ( Node1, Node2 )</tt>, Node1 and Nod2 being <tt>CDINode</tt> objects, googletest can't print good information in case of failure unless we tell it how to print <tt>CDINode</tt> objects. To teach googletest how to print nodes define the << operator as in the following example. To be more concrete, create a test helper (file) for the class <tt>CDINode</tt> which can then be used by many tests. Put the code into newly created files <tt>DINodeTestHelpers.(cpp|h)</tt> in the `TestHelpers' filter (aka folder). Note the naming convention: append `TestHelper' to the base name.
:CDINodeTestHelper.h:
<pre>
#pragma once

//..begin "UTF:Includes"
#include <iostream>
//..end "UTF:Includes"

//..begin "UTF:Forwards"
struct CDINode;
//..end "UTF:Forwards"

::std::ostream& operator<<(
  ::std::ostream& os, 
  const CDINode& i_Node);
</pre>
:CDINodeTestHelper.cpp:
<pre>
//..begin "UTF:Includes"
#include "StdAfx.h"
#include "DINodeTestHelpers.h"
#include "DINode.h"
//..end "UTF:Includes"

::std::ostream& operator<<(
  ::std::ostream& os, 
  const CDINode& i_Node) 
{
  return os << "NDS " << i_Node.m_fNodeDelayFactor << " , "
            << "Pos {" << i_Node.m_fXPos << "," << i_Node.m_fYPos << "}";  
}
</pre>
:See also [http://code.google.com/p/googletest/wiki/AdvancedGuide#Teaching_Google_Test_How_to_Print_Your_Values google test manual]. The manual also describes a 2nd way: defining a method <tt>PrintTo</tt> like so: <tt>void PrintTo(const CDINode&, ::std::ostream* os)</tt>.

==== Stream into assertion macro ====
Another way to print valuable information is to just stream into the <TT>EXEPCT_...</TT> / <TT>ASSERT_...</TT> macros as shown in the following examples. The information will be printed in case the assertion fails. In the following concrete example, we print also the relative position of a <tt>CDINode</tt>, Floride the absolute position stored within <tt>CDINode</tt>. 
<pre>
real64 fRelativePos1X = ...;
EXPECT_EQ( Node1, Node2 ) << "Node1 rel pos = " << fRelativePos1X << ...;
</pre>

See also [[UnitTest2_Practice#Test_rules_and_guidelines|Test rules and guidelines]] for what information you should stream into the <TT>EXEPCT_...</TT> / <TT>ASSERT_...</TT> macros and how you should do it.

==== Appropriate assertions ====
Using the most appropriate assertion leads to better, more informative output, see [[UnitTest2_Practice#Good_assertions_for_good_defect_localization|good assertions for good defect localization]].

=== Cookbook for writing tests ===

In case you find it hard to write a single test or to come up with the set of tests you need, the following advices might help you.


Cookbook to write a good single specification (aka test):
* Work in the agile way of advancing in little verified steps, preferably by using [[TDD]]. Each step should give you feedback whether you did it right.
* Write the test from it's back to it's start. I.e. first write the ASSERTs / EXPECTs in 'Then' clause & the 'verify' section, second write the 'When' clause & 'exercise' section, finally write the 'Given' clause & the 'setup' section. See also the [[Given When Then]] DSL. This because we tend to think about what we finally want first, which corresponds to the asserts in the 'Then' clause.
* For each given-when-then clause and test section pair, start with the given-when-then clause first. This because the clause is in prose, and we tend to think in words before we think in technical code. If you can't express the requirements clearly in prose, it is in general unlikely you can write correct and expressive test code.
* See the test fail before writing productive code satisfying the test. Benefits:
** You know the test specifies something which is really currently absent in the productive code.
** You know the test does not wrongly always succeed due to some mistake.
** You can inspect the output of the failing test and possibly improve it if it's not informative enough. See [[#Good_output_for_good_defect_localization|Good output for good defect localization]]


Random tips for writing a single specification (aka test):
* Test by giving an example what the program should do. I.e. an example of the initial state and/or the inputs plus what the corresponding expected outputs and/or resulting state are.
* Choose the most appropriate assertion macro, e.g. <TT>ASSERT_EQ</TT>, <TT>ASSERT_TRUE</TT> or <TT>ASSERT_DOUBLE_EQ</TT>. Advantages are 1) clearly describe what you want to test 2) more informative output in case the test fails. Details in [[UnitTest2_Practice#Good_assertions_for_good_defect_localization|good assertions for good defect localization]] 
* <TT>EXPECT_EQ/ASSERT_EQ</TT>'s first argument is the expected value, the 2nd argument is the actual value. Use the macros accordingly, else in case of failure the output is not as informative and clear as it could be.
* When an object/variable has to be passed to the UUT, but the content of that variable/object is irrelevant for the test, express that fact. In the example above, <tt>ANode</tt> is as the name says, just `a node', it's content is irrelevant. If the content however matters, name it again accordingly. E.g. if it's important for the test that the content is the one CDINode's default constructor produces, name the object e.g. <tt>DefaultNode</tt>. 
* The test case template from chapter [[UnitTest2_Practice#A_simple_empty_test_case|a simple empty test case]] is intended to be an easy template covering the general case. If you don't need the SetUp or TearDown methods, you can delete them. Heck, you might not even need the fixture class at all, consequently not even needing a header file, and use the <TT>TEST</TT> macros instead the <TT>TEST_F</TT>(fixture) macros. See also [http://code.google.com/p/googletest/wiki/Primer#Basic_Concepts googletest manual]


Cookbook to assemble a good set of specifications (aka tests) for a (new) feature:
Write the following set of specifications in order of [[TDD#The Transformation Priority Premise|The Transformation Priority Premise]].
* Exercise the `happy path' code which typically is a public or protected method. Exercising private methods is allowed, but that really is specifying implementation details which in general isn't the ideal  thing to do. See also [[Unit Test#White Box vs Black Box|White Box vs Black Box]].
* Verify direct outputs of the happy path
** The test name, it's verify section, the name of the method under test, the documentation of method under test should all say the same thing; ideally it's always exactly the same phrase.
* Verify alternative paths like `boundary conditions' and `error cases'
** Vary the SUT method arguments
** Vary the pre-test state of the SUT
** Control indirect inputs of the SUT via a test stub object
* Optionally verify indirect output behavior where it makes sense. Note that in general specifying implementation details isn't the ideal thing to do since it couples the specification too tightly to the SUT. See also [[Unit Test#White Box vs Black Box|White Box vs Black Box]].
** Intercept and verify outgoing method calls with mock objects
* The following shall help to have a measurement when you have enough tests:
** When you did proper TDD, that question is somewhat obsolete, since all the productive code you have exists only because you wrote a specification (aka test) forcing it to become existent.
** The [[#Definition of what a test really tests]] (''only'' the call(s) to the UUT in the exercise section is what really is tested) helps to recognize what in total really is tested so far, and thus also what is not tested yet.
** Since the set of specifications, all written in the [[Given When Then]] DSL, can also be seen as a state machine, see there, you're finished writing specifications when you defined all states and all transitions.
* Optimize test execution and maintainability
** Make the tests run faster
** Make the tests easier to understand and maintain


These chapters may also help to get into the right mindset to write good tests:
* [[TDD]]
* [[UnitTest2 Practice#Test rules and guidelines|test rules and guidelines]]
* [[Automated_Test#Program_specification_forms|program specification forms]]


The following is only discussion for the interested reader:
* This page defines that the only methods a test really tests are the calls to the UUT in the exercise section. ''All'' other calls are in this test untested and thus need their test somewhere else. That means that if these methods fail, the current test might fail too, which is bearable, but not optimal. Thus somehow strive to write testst that don't call anything, or at least as foolproof things as possible, so the methods in the exercise section are the only things that can (or at least are likely to) fail the current test.

=== Example UnitTest2 projects ===

These UnitTest2 projects adhere to all Flori UnitTest2 guidelines / ideas to a rather high degree:
* PC\Dispenser\DIDispenserSeq\UnitTest2
* PC\UnitTests\PC-UnitTest\FloriMockSupport\UnitTest2
* PC\Services\FloriSlaveLib\UnitTest2

== RTOS UnitTest2: How to enable UnitTest2 on RTOS==

To support UnitTest 2 on RTOS a few steps are needed.

=== GoogleTest, GoogleMock === 
UnitTest2 is based on the GoogleTest, GoogleMock framework. These are two separate git repositories on the server.

* You need the GoogleTest support as iDev projects. For this clone the two git repositories to your local environment:
   remote git path:  U:\Common\3rdPartyDevComponents\gmock.git
   local path:       W:\DieBonder\3rdPartyDevComponents\gmock

   remote git path:  U:\Common\3rdPartyDevComponents\gmock.git\gtest.git
   local path:       W:\DieBonder\3rdPartyDevComponents\gmock\gtest

Remark: GoogleTest is included in the GoogleMock path.

* Import the two projects in iDev and build it.
As a result the corresponding archives and xml feature file should be exported to W:\DieBonder\RTOS\Lib45 folder.

=== UnitTest2Manager for RTOS ===
* Import the new UnitTest2Manager project in iDev and build it.
As a result the corresponding archives and xml feature file should be exported to W:\DieBonder\RTOS\Lib45 folder.

=== RTOS UnitTest2 projects ===
* Create new RTOS UnitTest2 projects from your component and write your unit tests 2 with Google Test and Google Mock support. 
The referenced HowTo doc will be found here: [http://sharepoint/sites/Flori/Projects/Documents/DA/DA_2100_SW_Documents/Environment/02_HowTo/HowTo_RTOSUnitTest2.docx HowTo_RTOSUnitTest2].

* Attention: The UnitTest2 projects need config files from the Flori project.

  see path:
  C:\Program Files (x86)\Flori\DieBonder\RTSys\Config
  After a Daily Build installation this folder would be cleaned. 
  To get the required configuration build the main Flori project (D180, D188,...) and start at least once the HMI by Flori-Starter 
     or transfer RTOS config by McConfigurator.exe.

* Most of the rules and explanations written for PC UnitTest2 are also valid for the RTOS part. Please consider the corresponding documentation regarding TestDoubles, Patterns, writing tests, asserts and expections.

=== The global UnitTest2 project on RTOS ===

The already existing UnitTest2 project on RTOS (e.g. D180_UnitTest2) is not in use for the moment. This project is intended to be used for the Buildmachine to build in once all UnitTest2 code existing in the UnitTest2 folders of each project. As we know the slow build time of lots of projects compared to one single project, this will be the solution for faster builds.

== Patterns how to deal with common unit test problems ==
The true source for information on common unit test problems shall be here:
* Book 'Working effectively with legacy code'
* Book 'xUnit Test Patterns'
* [http://code.google.com/p/googletest/wiki/FAQ gtest FAQ]
* [http://code.google.com/p/googlemock/wiki/FrequentlyAskedQuestions gmock FAQ]
I think it doesn't make sense to repeat the content of the above information here on this wiki page. Still, as so often, there are multiple opinions on how to solve a given problem, so this chapter is an incomplete list of Flori biased patterns.

=== Tests wants to access private / protected members of the UUT class ===
Before you access private / protected members reconsider if this is really necessary - in general only accessing the public interface leads to better tests, see also [[Unit Test#White Box vs Black Box]]. 

* Derive a helper class from the UUT class and name it with 'CTesting' as prefix. With the using statement (being in the public section), you can give public access to the named member. That works for protected members in the UUT. For private members, the helper class has to be friend of the UUT class.
:Problem statement:
<pre>
class CFoo { private: void MyMethod(); }; // unit under test 

TEST( ..., ... ) { CFoo UUT; UUT.MyMethod(); } // compile error, MyMethod is private
</pre>
:Solution:
<pre>
class CFoo { friend class CTestingFoo; ... }

class CTestingFoo : public CFoo { public: using CFoo::MyMethod; };

TEST( ..., ... ) { CTestingFoo UUT; UUT.MyMethod(); } // now ok
</pre>
* Use the [http://en.wikipedia.org/wiki/Pimpl Pimpl idiom]. Details [http://code.google.com/p/googletest/wiki/AdvancedGuide#Testing_Private_Code here]
* Make your test friend of the test. However note that the gtest macros TEST and TEST_F each create a new class. So each test needs to be friend - use googletest's FRIEND_TEST macro to declare a friend. Details [http://code.google.com/p/googletest/wiki/AdvancedGuide#Testing_Private_Code here]
* Consider making the members public. Details in book 'Working effectively with legacy code', chapter 'The case of the Hidden Method' (page 138).


=== MSVC gives me warning C4301 or C4373 when I define a mock method with a const parameter. Why? ===
This is an addendum to the [http://code.google.com/p/googlemock/wiki/FrequentlyAskedQuestions#MSVC_gives_me_warning_C4301_or_C4373_when_I_define_a_mock_method same FAQ entry] in googlemock's FAQ. It is suggested to temporarily (lexically) disable and later below enable again this warning for the affected mock class header file like so:

<pre>
...
// see Flori specific googlemock FAQ 'MSVC gives me warning C4301 or C4373 ...'
#pragma warning( disable: 4373 )

/** */
class CMockPPPPickerModRTOSBase :
  public IPPPPickerModRTOSBase
{
...
};

#pragma warning( default: 4373 )
</pre>


=== Replace a global or class static method with a test double implementation ===
In short: Instead calling a global method directly, call it via CSE. E.g. call "CSE::Sleep(...)" instead just "Sleep(...)". See class CSE described in [[UnitTest2_Practice#Global_test_doubles]].

== Patterns how to deal with common Flori classes (AO, COM, ...) ==
This chapter descripes the patterns how a PC Flori component should be designed. The following UML class diagram is visualizing all this. It's source is in ObjectiF "PC/PC Services/CommonCtrlLib/Class Diagrams/Overview from test viewpoint". 

[[Image:Component_uml_class.png]]

=== PC: CoClass implementing COM interface ===
The advice is that this class should really only be a ''very thin'' facade ''only'' handling COM stuff and delegating the calls to the AO. The implementation is then trivial and there's no need to test it. There is also no need to create test doubles for it since no unit test will reference this class. 

However the CoClass typically derives from CCommonCtrl and thus inherits virtual methods such as e.g. GetStatus. Class CFoo of your component might wants to call GetStatus of the coclass. If you now want to test CFoo, you can't have the real object of the coclass, because as said we don't want to go that way. The idea is that for such cases we work with an 'internal' interface. E.g. the coclass for dispenser sequencer implements IDIDispenserSeqIntern. IDIDispenserSeqIntern provides methods which are used by CFoo and other classes in the component. The part 'intern' in the interface's name is to distinguish that interface from the already existing 'public' COM interface IDIDispenserSeq. The coclass, in its's constructor, registers itself to TSESingletonInterfaceService<IDIDispenserSeqIntern>. Classes like CFoo can then access the object implementing IDIDispenserSeqIntern via TSESingletonInterfaceService<IDIDispenserSeqIntern>::GetInterface(). During a UnitTest2, where there is no coclass object, a test double implementing IDIDispenserSeqIntern has to be created and registered to TSESingletonInterfaceService<IDIDispenserSeqIntern>.

=== PC: AO ===
The advice is that the ''only'' responsibility of this class is to maintain the queue. Put msgs into the queue and dispatch them. The implementation is delegated to other classes. AO's implementation is then trivial and there's no need to test it. Productive code which wants to call the implementation should directly call it, not via the AO. When we only have such cases, there is no need to have a test double for the AO since no unit tests references it. In a few occurrences, due to the asynchronity the AO can offer (but almost never does), productive code might reference the AO. I dont have a solution yet: maybe its feasible to use the real AO within such a unit test.

The AO typically derives from CCtrlAORtos or similar and thus inherits methods which are called by other classes in the component, say CFoo. From a first thought you now have troubles testing CFoo, since it needs somethin from the AO, but the AO is not available during the UnitTest2. The solution is to work with an interface like IDIDispenserSeqAO, which is implemented by the AO class. CFoo use that interface instead directly the AO. See also the previous subchapter on the coclass.

=== PC: Interfacecontainer ===
The test shall use the real interface container, together with its the real COM smart pointers. More details are in the COM subchapter.

=== COM ===
Howto write a new a test double class: In general there is a test double class per real COM coclass (typically that is a Flori component). Contrast this with having a test double class per COM interface. For details how to do write such a test double class, see the class comment of CUnknownFake (in FloriMockSupport). Since most COM coclasses are used by multiple projects, add new COM test double classes to the FloriMockSupport project, so every UnitTest2 project can profit from it. 

HowTo create and access a COM test double object during a test: Use the real interface container class of your component under test, together with its real COM smart pointers. The container's productive code, typically within the method DoConnectInterface, typically assigns real COM objects, retrieved using method GetComponentInterface, to each of its COM smart pointers. During the test, that sequence needs to be omitted and instead test double COM objects are assigned to the container's COM smart pointers. Naturally the test only needs to do that for COM smart pointers that are used during the test. The rest of the COM smart pointers are left being NULL. The test double COM objects must be treated like real COM objects: AddRef and Release have to be called according to the COM rules. If you ''always'' use COM smart pointers, you don't have to care explicitly about these rules. A notable consequence is that you have to assign objects created with new to the COM smart pointers. You can't pass objects on the stack to the COM smart pointers, and you can't explicitly delete test double COM objects - they are deleted implicitly within COM object's Release when the internal reference counter reaches zero.

The remaing part of the chapter are details for the interested reader:

Rational for howto write a test double class for a COM object: A COM object potentially can implement multiple COM interfaces. E.g. typically, a Flori COM object implements its 'main' COM interface, ICTComponent and ISupportErrorInfo. It's easiest to understand when the test double COM object implements the the same COM interfaces (or a subset of) as the real COM object.

=== PC: DB items ===
The DB items, usually seen in form of these the typdefs tPST_ExtReal tPST_ExtInteger etc, are testable by default. During UnitTest2, the actual implementation is replaced by a fake which does not access the real DB but works in memory. See also [[UnitTest2_Practice#A_specification_.28aka_test.29_using_faked_DB_items]]

=== PC: RTOS Communicator / Access ===
The advice is that the PC should access RTOS by the following means, listed after prefered priority, from highest to lowest:
# CExtendedIndelItemType<T> (aka tPST_INDELReal etc) or CINDELType<T> (aka tNO_PST_INDELReal etc). For usage, see [[UnitTest2_Practice#Global_test_doubles]]
# Use one or multiple classes which's ''only'' responsibility is to delegate calls to the INCO tree. These wrapper classes access INCO tree via CInterfaceContainerRtos::m_CCRtosServices or directly via the IRTOSCommunicator COM object. The wrapper class' implementation is then trivial and there's no need to test it. A test double class can be created easily by common means, e.g. have an interface which is implemented by the test double and the productive code, or e.g. by deriving the test double class from the productive code class.
# CFloriINCO, see [[UnitTest2_Practice#Global_test_doubles]]

== Global test helpers ==
An incomplete list of test helpers (assertions, printers, matchers, predicates, ...) Flori adds.

Test helpers for classes which are of Flori global interest are defined in project FloriMockSupport (PC\UnitTests\PC-UnitTest\FloriMockSupport). Please add helpers of global interest there instead of writing them only for your project.

=== Printers ===
Just assume that each type knows how to print itself. Since after writing a test you hopefully first check that it fails and look at the output ([[UnitTest2_Practice#Cookbook_for_writing_tests|Cookbok for writing tests]]), you always recognize if a type has no printer really. In such a case please help and add the required printer to the test helpers.

=== Assertions ===
An incomplete list of assertions Flori adds:

;<tt>(EXPECT|ASSERT)_[NO_]EASSERT</tt>
:<tt>EXPECT_EASSERT(statement)</tt> succeeds if statement hits an EASSERT. The other macros of the family are analogous.

;<tt>(ASSERT|EXPECT)_HRESULT_EQ</tt>
:Flori adds the dedicated macros <tt>(ASSERT|EXPECT)_HRESULT_EQ</tt> to the macros <tt>(ASSERT|EXPECT)_HRESULT_(SUCCEEDED|FAILED)</tt> already provided by googletest. However note that in general you want to use EXPECT_HRESULT_SUCCEEDED( ehr ) and not EXPECT_HRESULT_EQ( S_OK, ehr ), because in general you are only interested if the retruned HRESULT means succeeded or failed. What exactly the HRESULT was is in general irrelevant.

== Global settings ==
This chapter describes global settings which Flori introduces or changes from what Google defined

;Google mocks return S_OK by default
:The default return value for the return type (E)HRESULT is S_OK. The rational is that we want the most frequent occurring case to be convenient. It is much more frequent that a mock method should return S_OK than that it should return E_FAIL. This is actually also what gmock would do by default, since by default gmock returns the zero equivalent, and S_OKs integer value is zero.

;Google mocks are nice by default, not naggy
:Flori changed the default from naggy to nice. See also [http://code.google.com/p/googlemock/wiki/CookBook#The_Nice,_the_Strict,_and_the_Naggy this] chapter in googlemock's manual on the topic. Thus using the preferred ON_CALL, opposed to EXPECT_CALL, is even more practical. If you want a naggy mock you still can have one using the NaggyMock template class as explained in the manual. Rational: We prefer stubs over mocks, so stubs should be more convenient to work with than mocks.

;Trace log level is same as in production, i.e. TraceWarning
:If you want to change the log level, assign another value to ELogger::s_eActualTraceLevel


Details for the interested reader:

Most of above defaults are set in FloriGMockSupport's method 'main'.

== Global test doubles ==
Test doubles for classes / interfaces which are of Flori global interest are defined in the library FloriMockSupport (PC\UnitTests\PC-UnitTest\FloriMockSupport). Please add test doubles of global interest there instead of writing them only for your project.


=== CExtendedItemType CExtendedIndelItemType CINDELType ===
These classes are about encapsulating connection to DB and/or Indel/INCOtree for integers/reals/.... These classes are actually just wrappers around a concrete implementation. During production, the productive implementation is chosen, and during testing any test double, a fake by default. So in general you don't have to do anything explicit in the main project nor in the UnitTest2 project.
* CExtendedItemType<T> aka tPST_ExtReal etc
* CExtendedIndelItemType<T> aka tPST_INDELReal etc
* CINDELType<T> aka tNO_PST_INDELReal etc


=== CFloriINCO ===
The documention is within CFloriINCOImpl's Doxygen class comment.

=== CSE / global methods ===
The class CSE from library PC/Services/GlobalServices contains class static methods eventually wrapping the corresponding global methods. E.g. there is a CSE::Sleep(...) eventually wrapping the global Sleep(...) from windows.h. For details, see Doxygen comment of the class CSE, which is part of the project GlobalServices.



=== Miscellaneous global test doubles ===
Notable existing test double classes:
* Look into source when not finding what you search here on the wiki. You will find all available test doubles, also those not listed here on the wiki, by really looking into the FloriMockSupport project, project folder TestDoubles. 
* CCCServices
* CCommandController
* CCommonCtrl, CCommonCtrlRtos
* CCtrlAo
* ICCCapabilityCtrl
* CMCDynCombobox
* CTBLComClassBase
* ITBLTeachCapability
* ITBLMenuHandler
* COM:
:* IUnknown
:* ITeachSrv
:* ICTNotifyStatus (in CConfigMgrCOMItfMock)
:* ICMHardwareConfig (in CConfigMgrCOMItfMock)
:* IBondPositionDynamic
:* ISubstrateHdlCalibSrv
:* IPickPlaceCalibSrv
:* DATASTORE2Lib::IItem3

== Default test doubles ==

Some real objects are replaced by a test doubles by default. In general, in such cases it is a fake, opposed to e.g. a mock. If you wan't another test double or even the real object, you have to care about yourself in your test.

* The object wrapped by CExtendedItemType (commonly known by it's typedef aliases tPST_ExtReal etc): CExtendedItemTypeFake. 
* Likewise for CExtendedIndelItemType and CINDELType.
* CSE (to be precise CSEImpl) from GlobalServcies: the fake CSEFake. To use another test double, simply create a test double object, preferably on the stack. Upon its destruction, the previous test double will be used again. See class comment of CSE for more details.


Details for the interested reader:

Those default test double objects are set in FloriGMockSupport's method 'main'.

== Tools ==
This chapter presents and describes a couple of tools which may help you in your daily UnitTest2 work.

=== unittest2gen ===
UnitTest2 project generator. Creates a new unitest2 project, based on Flori's UnitTest2 template project. Also creates an solution in the Sources directory containing all three projects: main, (old) unittest, unittest2.

Only used so far on a real operating system - you're welcome to help to improve the script.

Mini-HowTo: In Bash shell (aka Git Bash, comes with Git/Cywgiwn):
<pre>
/w/DieBonder/PC/UnitTests/PC-UnitTest/unittest2gen/unittest2gen /w/DieBonder/PC/MyMps/MyProject 
</pre>

For more help, see the comment at the beginning of the script.

=== gmock_gen ===
Mock generator. Prints a googlemock class for any class you give to it. Googlemock's generator was adapted to meet Flori's guidelines.

Mini-HowTo: In Bash shell (aka Git Bash, comes with Git/Cywgiwn):
<pre>
/w/DieBonder/PC/UnitTests/PC-UnitTest/FloriMockGenerator/Sources/gmock_gen.py path-to-my-class/MyClass.h > MyClassMock.h
</pre>

For a tiny help, just run <tt>./gmock_gen.py</tt> without arguments.

=== testdox ===
Testdox extracts the test names, which really are specifications in the given when then DSL, from the test source files and creates a nicely readable output. Details can be found here [[Given_When_Then#TestDox|here]].

=== timeunittest2 ===
Prints timing statics for all Flori's UnitTest2s. This is on a test program level. If you need timings on a finer grained level, e.g. on test case or test level, inspect the output of running a UnitTest2. gtest prints those timings.

== Open points ==
* UnitTest2 on RTOS
* When an automated test fails on the build machine, that is an 'everything stops' event. ''No'' Git pushes except for the fix of the failed test. That might be a topic of the 'build environment' guild.
* Clear concepts and rules how to cope with all the different Flori equipment types (D180, D188, D186, ...)
** To be able to cope with the limited build machine resources, try to optimize building and running tests by building/running projects shared between configurations only once.
* Global test doubles for
** RTOSConnector / RTOSCommunication
** CommonCtrl
** CHLConfigParameter
** All services interfaces (e.g. CalibService, ConfigMgr ...). Some are already done: E.g. TeachService
** Rich error info (i.e. EHRESULT objects) with COM test doubles.
* Integrate testdox into our IDEs. When mouse hoovering over test name, a tool tip shows the nicely formatted prose equivalent.
* See also [[Googletest#Ideas|Googletest ideas]]

== See Also ==
* [[Testing]] Parent level page with all the testing links
