:encoding: UTF-8
// The markup language of this document is AsciiDoc

== CPU cache hierarchy

- Know which basic operations (acess (next, n-th, ...), insert, delete, find,
...) you do how often relative to each other. Mind that to e.g. insert/delete
an element, often you first have to find it first.
- Know how many items are in your collection.
- Know the characteristics of the underlying hardware. E.g. how expensive a CPU
cache miss is, how big the CPU cache is etc. Mind the prefetcher which gives
an additional cache level of infinite size _if_ memory is accessed
sequencially
- With the HW information and having an idea of the implementation details of an
algorithm you can estimate the hidden constant factors of the big O analysis
(in space and time, time affected by space due to CPU cache / memory
properties). Knowing which basic operations you do how often allows you to do
a big O analysis of the overall-task, inclusive an estimate of the hidden
factor. You also know for range of container size you have to do this overall
big O analysis.
* With todays consumer electronics CPU's, a CPU cache miss is in the range of
a few hundreds times slower than reading directly from cache.

The example. Per element:
1 insert-in-order (=find element just before the one to be inserted, insert), 1 find-nth, 1 remove.
Vector list and map all have O(n) overall, but vector has much smaller constant factor (a few hundreds times) because it accesses memory sequencially. List and map have high factor because they randomly access memory locations.  One of the things to note is that the overall O(n) is not very obvious for list, even less so for map.

Order statistic tree

- What is ``cache-friendly'' code?


== Performance measurements

- Glen suggests the tool `code performance'
- perf
 * http://www.brendangregg.com/linuxperf.html
 * off-cpu: http://www.brendangregg.com/offcpuanalysis.html
- strace / ltrace
- valgrind, cachegrind, callgrind, ...
- kcachegrind
- oprofile
- gprof
- systemtab
- dtrace
- Intel® VTune™ Amplifier 2016: https://software.intel.com/en-us/intel-vtune-amplifier-xe/try-buy


=== Brainstorming

* Measure first, tune what matters.  If you don't have all the relevant
  information, you can't make the right decision, and you can't have the
  right information until you measure.

* While using CPU or a ressource in general
 - Efficiency: Do the minimum amount of work needed to accomplish the task

* Reduce the amount of time the CPU is not used to accomplish my task/work
  - Reduce unproductively waiting for IO
  - Reduce unproductively waiting for `memory' access. I.e. data should come from registers / cpu cache hierarchy / RAM in that order.
    ** Mind false sharing
    ** Mind page faults / trashing
  - Reduce waiting time to be scheduled for CPU. I.e. reduce contention with other processes / threads.
  - Reduce waiting time on locks

* Use all ressources which can accomplish work
 - All cores / cpus. 
 - All io devices
 - All of faster storage before using slower storage (register, cpu cache, ram, disk, network)

* Make use of ressources efficiently. Use ressources the way they can operate the fastest
 - Sequencial access (disk, ram)
 - CPU / branche prediction: Conditional branches shall take the same branch in a row, and only seldom switch to taking the other one.
 

=== perf

As root, edit +++/etc/sysctl.conf+++, add the line +++kernel.perf_event_paranoid = -1+++, make it `active' with +++sysctl -p+++. See also http://unix.stackexchange.com/questions/14227/do-i-need-root-admin-permissions-to-run-userspace-perf-tool-perf-events-ar, http://www.cyberciti.biz/faq/howto-set-sysctl-variables/

Use the option -fno-omit-frame-pointer to compile.

++++++++++++++++++++++++++++++++++++++++++++++++++
perf record -g -s mycommand_and_args
perf report -g -T
++++++++++++++++++++++++++++++++++++++++++++++++++

+perf top+

==== Questions

- what does perf's children column really mean? I think it should mean 'percentage of all samples where this function is on the call stack'. But grepping e.g. BOGetKurs on the folded perf output and counting number of found lines I cannot verify that.

- where is my process/thread not doing anything but waiting

- perf-chidren of getBOKurs


=== Ressources
- http://www.linuxprogrammingblog.com/io-profiling[Profiling Input/Output performance]
- http://stackoverflow.com/questions/375913/what-can-i-use-to-profile-c-code-in-linux
- https://www.youtube.com/watch?v=fHNmRkzxHWs[Chandler Carruth "Efficiency with Algorithms Performance with Data Structures"]

== Inlining / (virtual) function call

- Instructions for a function call
 * Push registers on stack which are used by caller and might be modified by callee
 * Pass paremeters: Some are passed in registers, others by pushing them on the stack. For some, what is passed is not the object itself, but it's address. 
 * Pass return object's address as implicit parameter, see above.
 * Frame stuff, push IP (i.e. return addr), ...
 * Actuall call instruction
 * For the parameters not passed by registers, callee must read them from stack.
 * Frame stuff, ...
 * Return instruction

- What does virtual add to the above?

- When inlining, (much) more optimizations can be done. 

- When the produced code at call site for inlining is larger than the produced code for a function call (both times the optimized result). A larger footprint is the result. It's possible that more cpu cache misses result.

- C&plus;&plus;: +inline+ is a hint for the compiler to inline (and most compilers flat out ignore it since they know better), and a command to the linker.

- C&plus;&plus;: For inlining to work, the definition must be known to the compiler, i.e. the definition must be in the header [however there is also Time Optimization (LTO), and as part of that inlining]. That introduces compile time dependencies, and thus potentially slower builds.

- Virtual function call is an indirection at run-time.
 - Thus it makes live harder for (branch etc) prediction.
 - Two additional memory accesses (virtual function pointer and function's address), both of which might result in CPU cache misses. However there is prediction on that too: http://stackoverflow.com/questions/2141726/can-you-cache-a-virtual-function-lookup-in-c
 - Inlining is no longer possible



- http://stackoverflow.com/questions/1759300/when-should-i-write-the-keyword-inline-for-a-function-method
- http://stackoverflow.com/questions/145838/benefits-of-inline-functions-in-c


== call stack

A _stack frame_ (aka _frame_ aka _activation record_) contains information for
a function: its parameters, pushed IP (instruction pointer, the value in the
stack frame is often called _return adress_), pushed BP, its locals.

Register BP (_base pointer_ aka FP (_frame pointer_)) points to top stack
frame, i.e. the stack frame of the current function. The current function thus
can access its params and locals with a constant offsets relative to BP. If
there was only SP, the offsets of locals and params releative to SP would
change after each modification of SP. E.g. consider +alloca+.

Using the register BP as entry point and the BP member of each stack frame,
the stack frames build a singly linked list with the BP register as head ptr.

In this visualization the stack grows upwards:

--------------------------------------------------
frames     stack                         registers  text
        addr  description                        
                                              IP--+  f2:
f2's    35    local 2 of f2               <-- SP  |   .. ...
frame   36    local 1 of f2                       |   .. ...
        37 /--BP of previous stack frame  <-- BP  |   .. ...
        38 |  IP (IP when f2 was called)------+   +-->.. ...      
        39 |  param 2 for f2                  |       .. ...
        3A |  param 1 for f2                  |       
--------   |                                  |      f1:
f1's    3B |  local 2 of f1                   |       .. ...
frame   3C \  local 1 of f1                   +------>.. call (f2's addr)
        3D  =>BP of prevoius stack frame              .. ...
        3E /  IP (IP when f1 was called)------+       
        3F |  param 2 for f1                  |       
        40 |  param 1 for f1                  |       
--------   |                                  |       .. ...
...     41 |  ...                             +------>.. call (f1's addr)
        42 \=>BP                                      .. ...
--------------------------------------------------

A typical sequence of events might look like this:

--------------------------------------------------
   function call                           return from function
1. push params (decreases SP)              10. SP += sizeof(params)
2. call fun (pushes IP,                    9. return (pops IP,
           decreases SP,                           increases SP)
           reseats IP)
3. push BP (decreases SP)                  8. pop BP
4. BP = SP                                 7. SP = BP
5. alloc locals (decrease SP)              6. -
--------------------------------------------------


References:
- http://www.cs.princeton.edu/courses/archive/spr06/cos320/notes/Stack-handout.pdf


=== Howto use a stack trace (aka stack backtrace)

1) extract function name from stacktrace
[01]: 0x00002b162f974735 BOBuchhaltungTaskWorker::adhoc(BOManager*, BOBuchhaltungTaskDataElement*)+0x85 (at 0x00002b162f974735 in /home/xentis/xentis/packages/XENTIS/lib/libAmisBO.so)
...

2) get relative address of that function symbol
$ nm /home/xentis/xentis/packages/XENTIS/lib/libAmisBO.so | c++filt | grep BOBuchhaltungTaskWorker::adhoc
000000000074f6b0 T BOBuchhaltungTaskWorker::adhoc(BOManager*, BOBuchhaltungTaskDataElement*)

3) use gdb to disassemble the function
gdb /home/xentis/xentis/packages/XENTIS/lib/libAmisBO.so
disass 0x000000000074f6b0

4) stacktrace said its the instruction with offest +0x85 (+133 dec), so in the disassembly:
   0x000000000074f735 <+133>:	mov    (%r12),%rax


== Error handling

Use asserts for conditions during development that can never be true if all your code is correct. `cannot be' means `will never happen if the program is correct', or `it is under my control'. Then again who is `my', what parts of the program are we talking about? When an exception fires it means that the program is in an ill state and data might be corrupt. It makes no sense to continue the current unit of work on such a basis. I.e. don't use asserts to check preconditions (since in the release version the check wont be there and the precondition would be violated).



Better talk about unit of work (program/progress/thread/cmd of loop/function) than of program.

Depending on the program
- The user prefers that the program gracefully continues, altough it doesn't do exactly what it should. The displayed/outputed data might be incorrect.
- The user prefers that the behaviour/data of the program is absolutely correct. He can better tolerate that the program terminates, maybe even ungracefully.


- https://msdn.microsoft.com/en-us/library/hh279678.aspx[Errors and Exception Handling (Modern C++)]



== Static / Dynamic code analysis

https://clang.llvm.org/docs/index.html


=== clang tidy

clang-tidy is a LibTooling-based tool. It can be used as a frontend for the static analyzer checkers (clang-analyzer-*).


=== clang static analizer

Tutorial

- scan-build cmake ...
- scan-build [generator-cmd, e.g. make] ...


Notes:

- The `clang --analyze' command should be viewed as an implementation detail. You should rely on scan-build.


=== AddressSanitizer (ASan)

Memory error dedector. But _not_ a leak dedector, however apparently LeakSanitizer is integrated by default.

- Needs compiler instrumentation module. Available at least for gcc (4.8) and clang (3.1). Compile with -fsanitize=address.
- Needs a runtime lib which replaces the malloc/free functions. Link with -fsanitize=address (use clang++, not ld, says the manual).
- Allows to ignore certain functions. One can use the no_sanitize_address attribute supported by Clang (3.3+) and GCC (4.8+).
- Allegedly has no false positives
- Apparently relatively fast. Slowdown ~2x.
- Uses a lot of memory. Stack ~3x, heap depends on allocation sizes (larger relative overhead for smaller allocations).

Consequences:

- Does not handle libraries built without -fsanitize=address (because asan depends on compiler instrumentation module)

Recommendations:

- Better stack traces: compile with -fno-omit-frame-pointer -fno-optimize-sibling-calls -O1 (to disable inlining)
- -01 for acceptable performance
- Set env variable ASAN_SYMBOLIZER_PATH to path of llvm-symbolizer to symbolize output
- Enable address-use-after-scope: Compile with -fsanitize-address-use-after-scope. To turn off at runtime: Env variable ASAN_OPTIONS=detect_stack_use_after_scope=0 (colon separated)
- redzone size of up to 128: ASAN_OPTIONS=redzone=128 (colon separated)
- debuggig:
 * stop before an asan error: breakpoint on __asan::ReportGenericError.
 * stop after asan error: breakpoint on __sanitizer::Die or use ASAN_OPTIONS=abort_on_error=1.
- Env variable ASAN_OPTIONS=check_initialization_order=1.


=== LeakSanitizer (LSan)

Run-time memory leak detector. Integrated into AddressSanitizer, see there. To use LSan in standalone mode, link with -fsanitize=leak.


=== Undefinded behaviour sanitizer (UBSan)

- Modifies program at compile time. Compile with -fsanitize=undefined (clang 3.3). (gcc also has this option, but I don't know if it's the same sanitizer)
 * Enables all checks other than unsigned-integer-overflow and the nullability-*.

Recommendations:
- Nicer stack trace: Compile with -g -fno-omit-frame-pointer. Run with env variable UBSAN_OPTIONS=print_stacktrace=1. Make sure llvm-symbolizer binary is in PATH.


=== cppchecker




== Build tools / Libraries

=== Linker
gold

=== Compiler
gcc, clang

=== Build
build system: cmake, ant, maven
?: ninja, make


=== Dynamic memory allocation
tcmalloc



== Information managers / note taking

Consider using Evernote: https://evernote.com/intl/de/?var=1
